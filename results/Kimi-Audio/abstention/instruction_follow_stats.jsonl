{"file": "NSynth_music_source_classification_test.jsonl", "total": 100, "one_hit": 93, "others": 7, "abstention_rate": 7.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[14, "b", 0, []], [19, "c", 0, []], [24, "b", 0, []], [31, "b", 0, []], [47, "h", 0, []], [59, "e", 0, []], [86, "bass_guitar,guitar,plucked_string_instrument,musical_instrument,music", 0, []]]}
{"file": "vctk_gender_classification_test.jsonl", "total": 100, "one_hit": 100, "others": 0, "abstention_rate": 0.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": []}
{"file": "vctk_age_classification_test.jsonl", "total": 100, "one_hit": 95, "others": 5, "abstention_rate": 5.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[16, "based on the provided information, it is not possible to accurately determine the age group of the speaker.", 0, []], [24, "the age group of the speaker is not specified in the given information.", 0, []], [67, "the speaker's age group cannot be determined from the provided audio clip.", 0, []], [78, "based on the information provided, it is not possible to accurately determine the speaker's age group.", 0, []], [98, "c", 0, []]]}
{"file": "vocalsound_gender_classification_test.jsonl", "total": 200, "one_hit": 174, "others": 26, "abstention_rate": 13.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[26, "f", 0, []], [28, "f", 0, []], [29, "sigh", 0, []], [33, "a", 0, []], [46, "a", 0, []], [48, "cough", 0, []], [53, "inhale", 0, []], [66, "f", 0, []], [74, "coughing does not indicate gender.", 0, []], [78, "a", 0, []]]}
{"file": "accentdb_AI_classification_test.jsonl", "total": 100, "one_hit": 94, "others": 6, "abstention_rate": 6.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[15, "child speech, speech, human voice", 0, []], [31, "child_s_speech_and_kid_s_speech", 0, []], [42, "female", 0, []], [48, "s", 0, []], [52, "child_s_speech_and_kid_speech,speech,human_voice", 0, []], [82, "female_speech_and_woman_speaking,speech,human_voice", 0, []]]}
{"file": "common-voice_accent_classification_test.jsonl", "total": 100, "one_hit": 79, "others": 21, "abstention_rate": 21.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[3, "the speaker's accent is american english.", 0, []], [5, "the speech has a distinct american accent, characterized by the use of the r-dropping feature and the vowel shift in certain words.", 0, []], [8, "the speech exhibits a distinct accent that is not listed in the options. it is likely a unique or non-standard accent.", 0, []], [11, "the speaker's accent is classified as northern irish english.", 2, ["northern irish", "irish english"]], [12, "the speaker's accent is likely from northern ireland, as indicated by the distinct pronunciation of certain words and the overall intonation pattern.", 0, []], [22, "ireland english", 0, []], [24, "without the actual audio, i can't provide a specific classification. however, i can tell you that each accent has its own unique features such as vowel shifts, diphthongs, and stress patterns.", 0, []], [25, "australia english", 0, []], [26, "without the actual audio, it's impossible to accurately determine the accent. however, the speaker's accent could be identified by analyzing the specific phonetic features, intonation patterns, and stress patterns unique to each accent.", 0, []], [28, "without the actual audio, i can't determine the accent. however, if you had the audio, you could use a speech recognition api to identify the accent.", 0, []]]}
{"file": "meld_SV_classification_test.jsonl", "total": 100, "one_hit": 89, "others": 11, "abstention_rate": 11.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[2, "without specific audio features, it's challenging to accurately classify the speaker. however, the presence of laughter suggests a friendly, casual conversation.", 0, []], [14, "a", 0, []], [19, "i'm sorry, but i can't provide the answer without the audio clip.", 0, []], [22, "the speaker's voice is not distinctive enough to be confidently classified into one of the predefined categories.", 0, []], [27, "d", 0, []], [42, "the speaker's voice is not distinctive enough to be classified into one of the predefined categories.", 0, []], [51, "without specific audio cues, it's impossible to accurately identify the speaker.", 0, []], [75, "without specific audio features, it's impossible to accurately classify the speaker.", 0, []], [76, "yes,", 0, []], [82, "without specific audio features, it's challenging to accurately classify the speaker.", 0, []]]}
{"file": "vctk_accent_classification_test.jsonl", "total": 100, "one_hit": 89, "others": 11, "abstention_rate": 11.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[3, "ireland", 0, []], [12, "i", 0, []], [20, "d", 0, []], [25, "c", 0, []], [63, "a", 0, []], [72, "i", 0, []], [77, "d", 0, []], [82, "f", 0, []], [90, "a", 0, []], [93, "f", 0, []]]}
{"file": "voxceleb_gender_classification_test.jsonl", "total": 100, "one_hit": 100, "others": 0, "abstention_rate": 0.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": []}
{"file": "CREMAD_EIE_classification_test.jsonl", "total": 100, "one_hit": 95, "others": 5, "abstention_rate": 5.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[5, "e", 0, []], [21, "d", 0, []], [28, "e!e", 0, []], [81, "d", 0, []], [85, "e", 0, []]]}
{"file": "common-voice_age_classification_test.jsonl", "total": 100, "one_hit": 77, "others": 23, "abstention_rate": 23.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[4, "f", 0, []], [7, "a", 0, []], [11, "the man's voice is deep and mature, suggesting he is likely in his fifties or sixties.", 2, ["sixties", "fifties"]], [13, "the speaker's age cannot be accurately determined from the provided speech sample.", 0, []], [15, "the speaker's age cannot be accurately determined from the provided speech sample.", 0, []], [21, "the speaker's age cannot be accurately determined from the provided speech sample.", 0, []], [30, "the speaker's age is difficult to determine from the provided information.", 0, []], [39, "the speaker's age is difficult to determine from the audio alone. however, the presence of a young male voice suggests that the speaker is likely in his twenties or thirties.", 2, ["twenties", "thirties"]], [48, "the speaker's voice, while not explicitly indicating age, suggests a mature adult, possibly in the seventies or eighties.", 2, ["eighties", "seventies"]], [51, "the speaker's voice is deep and mature, suggesting an age group of fifties or sixties.", 2, ["sixties", "fifties"]]]}
{"file": "Synthetic_Audio_Classification_test.jsonl", "total": 100, "one_hit": 93, "others": 7, "abstention_rate": 7.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[8, "based on the provided information, it is likely that the speech is ai-generated.", 0, []], [12, "the speech is likely ai-generated, as it lacks the natural variations and emotional nuances typically found in human speech.", 0, []], [32, "the speech appears to be human-generated, as it lacks the mechanical or robotic qualities typically associated with ai-generated speech.", 0, []], [34, "the speech is likely ai-generated, as it lacks the natural variations and emotional nuances typically found in human speech.", 0, []], [52, "based on the provided information, it is likely that the speech is ai-generated.", 0, []], [57, "the speech is likely ai-generated, as it lacks the natural variations and emotional nuances typically found in human speech.", 0, []], [64, "the speech is likely ai-generated, as it contains unnatural pauses and lacks the natural flow of human speech.", 0, []]]}
{"file": "NSynth_instrument_classification_test.jsonl", "total": 100, "one_hit": 96, "others": 4, "abstention_rate": 4.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[4, "b", 0, []], [58, "b", 0, []], [81, "guitar,keyboard", 2, ["guitar", "keyboard"]], [90, "b", 0, []]]}
{"file": "common-voice_gender_classification_test.jsonl", "total": 100, "one_hit": 100, "others": 0, "abstention_rate": 0.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": []}
{"file": "vocalsound_vocal_classification_test.jsonl", "total": 200, "one_hit": 199, "others": 1, "abstention_rate": 0.5, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[189, "s", 0, []]]}
{"file": "meld_ER_classification_test.jsonl", "total": 100, "one_hit": 93, "others": 7, "abstention_rate": 7.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[1, "a", 0, []], [19, "the speaker's tone and vocal patterns suggest a joyful emotion.", 0, []], [26, "a", 0, []], [39, "e", 0, []], [46, "e", 0, []], [47, "e", 0, []], [75, "b", 0, []]]}
{"file": "velocity_classification_test.jsonl", "total": 100, "one_hit": 99, "others": 1, "abstention_rate": 1.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[65, "without specific information about the note's intensity, it's impossible to accurately classify its velocity.", 0, []]]}
{"file": "CREMAD_ER_classification_test.jsonl", "total": 100, "one_hit": 94, "others": 6, "abstention_rate": 6.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[3, "d", 0, []], [15, "d", 0, []], [26, "d", 0, []], [40, "d", 0, []], [48, "e", 0, []], [90, "surprise", 0, []]]}
{"file": "meld_EIE_classification_test.jsonl", "total": 100, "one_hit": 98, "others": 2, "abstention_rate": 2.0, "checked_at": "2025-06-24T02:54:30", "bad_examples": [[0, "the audio does not provide enough information to determine the emotional intensity.", 0, []], [3, "the speaker's emotional intensity is neutral, as the tone of the conversation does not indicate strong positive or negative emotions.", 3, ["neutral", "negative", "positive"]]]}
